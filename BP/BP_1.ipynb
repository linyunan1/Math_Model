{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import mpl\n",
    "%matplotlib inline\n",
    "\n",
    "# 正常显示中文标签\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# 正常显示负号\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# 显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "# 显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 从硬盘读取数据进入内存\n",
    "df = pd.read_excel(\"Molecular_Descriptor.xlsx\")\n",
    "df1 = pd.read_excel(\"ADMET.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方差过滤\n",
    "\n",
    "count = 0\n",
    "column = []\n",
    "\n",
    "for j in range(df.shape[1] - 1):\n",
    "    if df.iloc[:,j + 1].std() == 0:\n",
    "        column.append(j + 1)\n",
    "\n",
    "#for i in column:\n",
    "df.drop(labels = df.columns[column], axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9190556492411467\n"
     ]
    }
   ],
   "source": [
    "#特征选择\n",
    "\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#将数据划分为标签和特征\n",
    "X = df.drop(['SMILES'],axis = 1).values\n",
    "y = df1['Caco-2'].values\n",
    "\n",
    "# 分训练集和测试集\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier #分类\n",
    "\n",
    "feature_name = df.drop(['SMILES'],axis = 1).columns\n",
    "rfc = RandomForestClassifier(n_estimators=60, random_state=0) # 随机森林实例化\n",
    "# 训练\n",
    "rfc = rfc.fit(Xtrain,Ytrain)\n",
    "# 得分\n",
    "score_Random_Forest = rfc.score(Xtest,Ytest)\n",
    "print(score_Random_Forest)\n",
    "\n",
    "r = [*zip(feature_name,rfc.feature_importances_)]\n",
    "r.sort(key=lambda x:x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SP-1',\n",
       " 'nBonds',\n",
       " 'MW',\n",
       " 'Kier3',\n",
       " 'WTPT-1',\n",
       " 'MLFER_L',\n",
       " 'ETA_Beta_s',\n",
       " 'WPATH',\n",
       " 'Zagreb',\n",
       " 'ETA_Alpha',\n",
       " 'VP-0',\n",
       " 'nHeavyAtom',\n",
       " 'minaaO',\n",
       " 'sumI',\n",
       " 'MLFER_S',\n",
       " 'McGowan_Volume',\n",
       " 'ETA_Eta_R_L',\n",
       " 'MLFER_BH',\n",
       " 'ECCEN',\n",
       " 'Kier1',\n",
       " 'Kier2',\n",
       " 'ETA_Eta_R',\n",
       " 'VABC',\n",
       " 'ETA_Beta',\n",
       " 'SaaO',\n",
       " 'maxaaO',\n",
       " 'SP-0',\n",
       " 'SP-3',\n",
       " 'TopoPSA',\n",
       " 'apol',\n",
       " 'FMF',\n",
       " 'naAromAtom',\n",
       " 'nAtom',\n",
       " 'ATSp2',\n",
       " 'SP-2',\n",
       " 'SP-7',\n",
       " 'nBondsS',\n",
       " 'ATSm2',\n",
       " 'ATSm5',\n",
       " 'SCH-6',\n",
       " 'MDEC-22',\n",
       " 'MLFER_E',\n",
       " 'SsCH3',\n",
       " 'minaasC',\n",
       " 'ATSm1',\n",
       " 'nwHBa',\n",
       " 'MDEC-12',\n",
       " 'SC-5',\n",
       " 'SCH-5',\n",
       " 'naaO',\n",
       " 'ETA_dEpsilon_D',\n",
       " 'ATSp5',\n",
       " 'BCUTp-1l',\n",
       " 'ETA_dBeta',\n",
       " 'naaN',\n",
       " 'nT5Ring',\n",
       " 'ETA_Shape_Y',\n",
       " 'nAromBond',\n",
       " 'minHBint5',\n",
       " 'maxHBd']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特征个数选择\n",
    "\n",
    "count = []\n",
    "\n",
    "for i in range(60):\n",
    "    count.append(r[i][0])\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[count].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                610       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 632\n",
      "Trainable params: 632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6089 - val_loss: 0.6581 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.6253 - accuracy: 0.6107 - val_loss: 0.6329 - val_accuracy: 0.5840 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.5981 - accuracy: 0.6107 - val_loss: 0.6071 - val_accuracy: 0.5867 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.5706 - accuracy: 0.6409 - val_loss: 0.5812 - val_accuracy: 0.6080 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.5427 - accuracy: 0.7342 - val_loss: 0.5552 - val_accuracy: 0.6693 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.5147 - accuracy: 0.8000 - val_loss: 0.5295 - val_accuracy: 0.7440 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.4873 - accuracy: 0.8347 - val_loss: 0.5050 - val_accuracy: 0.7867 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.4616 - accuracy: 0.8462 - val_loss: 0.4825 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.4382 - accuracy: 0.8507 - val_loss: 0.4625 - val_accuracy: 0.8320 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.4177 - accuracy: 0.8560 - val_loss: 0.4451 - val_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.4000 - accuracy: 0.8613 - val_loss: 0.4303 - val_accuracy: 0.8507 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.3851 - accuracy: 0.8649 - val_loss: 0.4179 - val_accuracy: 0.8480 - lr: 0.0010\n",
      "Epoch 13/10000\n",
      "113/113 [==============================] - 0s 733us/step - loss: 0.3726 - accuracy: 0.8658 - val_loss: 0.4075 - val_accuracy: 0.8480 - lr: 0.0010\n",
      "Epoch 14/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.3622 - accuracy: 0.8711 - val_loss: 0.3989 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 15/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.3534 - accuracy: 0.8747 - val_loss: 0.3916 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 16/10000\n",
      "113/113 [==============================] - 0s 771us/step - loss: 0.3461 - accuracy: 0.8729 - val_loss: 0.3854 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 17/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.3399 - accuracy: 0.8738 - val_loss: 0.3802 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 18/10000\n",
      "113/113 [==============================] - 0s 778us/step - loss: 0.3347 - accuracy: 0.8756 - val_loss: 0.3758 - val_accuracy: 0.8587 - lr: 0.0010\n",
      "Epoch 19/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.3302 - accuracy: 0.8738 - val_loss: 0.3719 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 20/10000\n",
      "113/113 [==============================] - 0s 771us/step - loss: 0.3262 - accuracy: 0.8773 - val_loss: 0.3685 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 21/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.3228 - accuracy: 0.8773 - val_loss: 0.3655 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 22/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.3198 - accuracy: 0.8773 - val_loss: 0.3628 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 23/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.3172 - accuracy: 0.8773 - val_loss: 0.3603 - val_accuracy: 0.8587 - lr: 0.0010\n",
      "Epoch 24/10000\n",
      "113/113 [==============================] - 0s 722us/step - loss: 0.3148 - accuracy: 0.8791 - val_loss: 0.3581 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 25/10000\n",
      "113/113 [==============================] - 0s 767us/step - loss: 0.3126 - accuracy: 0.8818 - val_loss: 0.3561 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 26/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.3106 - accuracy: 0.8844 - val_loss: 0.3542 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 27/10000\n",
      "113/113 [==============================] - 0s 774us/step - loss: 0.3088 - accuracy: 0.8862 - val_loss: 0.3524 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 28/10000\n",
      "113/113 [==============================] - 0s 763us/step - loss: 0.3071 - accuracy: 0.8889 - val_loss: 0.3507 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 29/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.3055 - accuracy: 0.8880 - val_loss: 0.3491 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 30/10000\n",
      "113/113 [==============================] - 0s 778us/step - loss: 0.3041 - accuracy: 0.8880 - val_loss: 0.3476 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 31/10000\n",
      "113/113 [==============================] - 0s 776us/step - loss: 0.3027 - accuracy: 0.8916 - val_loss: 0.3462 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 32/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.3014 - accuracy: 0.8916 - val_loss: 0.3449 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 33/10000\n",
      "113/113 [==============================] - 0s 782us/step - loss: 0.3002 - accuracy: 0.8916 - val_loss: 0.3436 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 34/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2990 - accuracy: 0.8916 - val_loss: 0.3423 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 35/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2979 - accuracy: 0.8933 - val_loss: 0.3411 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 36/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2969 - accuracy: 0.8933 - val_loss: 0.3399 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 37/10000\n",
      "113/113 [==============================] - 0s 727us/step - loss: 0.2959 - accuracy: 0.8933 - val_loss: 0.3388 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 38/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.2949 - accuracy: 0.8960 - val_loss: 0.3377 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 39/10000\n",
      "113/113 [==============================] - 0s 763us/step - loss: 0.2940 - accuracy: 0.8951 - val_loss: 0.3367 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 40/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2931 - accuracy: 0.8951 - val_loss: 0.3357 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 41/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.2922 - accuracy: 0.8951 - val_loss: 0.3347 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 42/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.2914 - accuracy: 0.8951 - val_loss: 0.3337 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 43/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2906 - accuracy: 0.8942 - val_loss: 0.3328 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 44/10000\n",
      "113/113 [==============================] - 0s 800us/step - loss: 0.2898 - accuracy: 0.8933 - val_loss: 0.3319 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 45/10000\n",
      "113/113 [==============================] - 0s 787us/step - loss: 0.2890 - accuracy: 0.8942 - val_loss: 0.3310 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 46/10000\n",
      "113/113 [==============================] - 0s 822us/step - loss: 0.2883 - accuracy: 0.8951 - val_loss: 0.3301 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 47/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2876 - accuracy: 0.8951 - val_loss: 0.3293 - val_accuracy: 0.8693 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2869 - accuracy: 0.8933 - val_loss: 0.3285 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 49/10000\n",
      "113/113 [==============================] - 0s 767us/step - loss: 0.2862 - accuracy: 0.8951 - val_loss: 0.3277 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 50/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2856 - accuracy: 0.8942 - val_loss: 0.3269 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 51/10000\n",
      "113/113 [==============================] - 0s 829us/step - loss: 0.2850 - accuracy: 0.8942 - val_loss: 0.3262 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 52/10000\n",
      "113/113 [==============================] - 0s 827us/step - loss: 0.2843 - accuracy: 0.8942 - val_loss: 0.3255 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 53/10000\n",
      "113/113 [==============================] - 0s 803us/step - loss: 0.2837 - accuracy: 0.8951 - val_loss: 0.3247 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 54/10000\n",
      "113/113 [==============================] - 0s 768us/step - loss: 0.2832 - accuracy: 0.8942 - val_loss: 0.3241 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 55/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2826 - accuracy: 0.8942 - val_loss: 0.3234 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 56/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2820 - accuracy: 0.8942 - val_loss: 0.3227 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 57/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2815 - accuracy: 0.8951 - val_loss: 0.3221 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 58/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.2810 - accuracy: 0.8951 - val_loss: 0.3215 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 59/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2805 - accuracy: 0.8951 - val_loss: 0.3209 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 60/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2800 - accuracy: 0.8951 - val_loss: 0.3203 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 61/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2795 - accuracy: 0.8951 - val_loss: 0.3197 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 62/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.2790 - accuracy: 0.8951 - val_loss: 0.3191 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 63/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2785 - accuracy: 0.8951 - val_loss: 0.3186 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 64/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2781 - accuracy: 0.8951 - val_loss: 0.3181 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 65/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2776 - accuracy: 0.8951 - val_loss: 0.3175 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 66/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2772 - accuracy: 0.8951 - val_loss: 0.3170 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 67/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.2768 - accuracy: 0.8942 - val_loss: 0.3165 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 68/10000\n",
      "113/113 [==============================] - 0s 774us/step - loss: 0.2764 - accuracy: 0.8942 - val_loss: 0.3161 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 69/10000\n",
      "113/113 [==============================] - 0s 811us/step - loss: 0.2760 - accuracy: 0.8942 - val_loss: 0.3156 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 70/10000\n",
      "113/113 [==============================] - 0s 783us/step - loss: 0.2756 - accuracy: 0.8942 - val_loss: 0.3151 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 71/10000\n",
      "113/113 [==============================] - 0s 770us/step - loss: 0.2752 - accuracy: 0.8942 - val_loss: 0.3147 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 72/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2748 - accuracy: 0.8951 - val_loss: 0.3142 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 73/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2744 - accuracy: 0.8951 - val_loss: 0.3138 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 74/10000\n",
      "113/113 [==============================] - 0s 772us/step - loss: 0.2741 - accuracy: 0.8951 - val_loss: 0.3134 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 75/10000\n",
      "113/113 [==============================] - 0s 851us/step - loss: 0.2737 - accuracy: 0.8960 - val_loss: 0.3130 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 76/10000\n",
      "113/113 [==============================] - 0s 872us/step - loss: 0.2734 - accuracy: 0.8960 - val_loss: 0.3126 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 77/10000\n",
      "113/113 [==============================] - 0s 873us/step - loss: 0.2730 - accuracy: 0.8960 - val_loss: 0.3122 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 78/10000\n",
      "113/113 [==============================] - 0s 777us/step - loss: 0.2727 - accuracy: 0.8969 - val_loss: 0.3118 - val_accuracy: 0.8773 - lr: 0.0010\n",
      "Epoch 79/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2724 - accuracy: 0.8969 - val_loss: 0.3115 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 80/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2720 - accuracy: 0.8960 - val_loss: 0.3111 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 81/10000\n",
      "113/113 [==============================] - 0s 804us/step - loss: 0.2717 - accuracy: 0.8969 - val_loss: 0.3108 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 82/10000\n",
      "113/113 [==============================] - 0s 806us/step - loss: 0.2714 - accuracy: 0.8969 - val_loss: 0.3104 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 83/10000\n",
      "113/113 [==============================] - 0s 831us/step - loss: 0.2711 - accuracy: 0.8969 - val_loss: 0.3101 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 84/10000\n",
      "113/113 [==============================] - 0s 783us/step - loss: 0.2708 - accuracy: 0.8978 - val_loss: 0.3098 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 85/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2705 - accuracy: 0.8987 - val_loss: 0.3095 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 86/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2702 - accuracy: 0.8996 - val_loss: 0.3091 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 87/10000\n",
      "113/113 [==============================] - 0s 713us/step - loss: 0.2700 - accuracy: 0.8996 - val_loss: 0.3088 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 88/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2697 - accuracy: 0.8996 - val_loss: 0.3085 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 89/10000\n",
      "113/113 [==============================] - 0s 774us/step - loss: 0.2694 - accuracy: 0.8996 - val_loss: 0.3083 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 90/10000\n",
      "113/113 [==============================] - 0s 776us/step - loss: 0.2692 - accuracy: 0.8996 - val_loss: 0.3080 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 91/10000\n",
      "113/113 [==============================] - 0s 815us/step - loss: 0.2689 - accuracy: 0.9004 - val_loss: 0.3077 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 92/10000\n",
      "113/113 [==============================] - 0s 819us/step - loss: 0.2686 - accuracy: 0.9004 - val_loss: 0.3074 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 93/10000\n",
      "113/113 [==============================] - 0s 788us/step - loss: 0.2684 - accuracy: 0.8996 - val_loss: 0.3072 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 94/10000\n",
      "113/113 [==============================] - 0s 819us/step - loss: 0.2681 - accuracy: 0.8996 - val_loss: 0.3069 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 95/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2679 - accuracy: 0.8996 - val_loss: 0.3067 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 96/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2676 - accuracy: 0.8996 - val_loss: 0.3064 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 97/10000\n",
      "113/113 [==============================] - 0s 799us/step - loss: 0.2674 - accuracy: 0.8996 - val_loss: 0.3062 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 98/10000\n",
      "113/113 [==============================] - 0s 863us/step - loss: 0.2672 - accuracy: 0.8996 - val_loss: 0.3059 - val_accuracy: 0.8720 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/10000\n",
      "113/113 [==============================] - 0s 861us/step - loss: 0.2669 - accuracy: 0.8996 - val_loss: 0.3057 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 100/10000\n",
      "113/113 [==============================] - 0s 829us/step - loss: 0.2667 - accuracy: 0.9004 - val_loss: 0.3055 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 101/10000\n",
      "113/113 [==============================] - 0s 844us/step - loss: 0.2665 - accuracy: 0.9004 - val_loss: 0.3053 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 102/10000\n",
      "113/113 [==============================] - 0s 796us/step - loss: 0.2663 - accuracy: 0.9004 - val_loss: 0.3050 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 103/10000\n",
      "113/113 [==============================] - 0s 831us/step - loss: 0.2661 - accuracy: 0.9004 - val_loss: 0.3048 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 104/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2659 - accuracy: 0.9004 - val_loss: 0.3046 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 105/10000\n",
      "113/113 [==============================] - 0s 770us/step - loss: 0.2656 - accuracy: 0.9013 - val_loss: 0.3044 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 106/10000\n",
      "113/113 [==============================] - 0s 834us/step - loss: 0.2654 - accuracy: 0.9013 - val_loss: 0.3042 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 107/10000\n",
      "113/113 [==============================] - 0s 795us/step - loss: 0.2652 - accuracy: 0.9013 - val_loss: 0.3040 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 108/10000\n",
      "113/113 [==============================] - 0s 802us/step - loss: 0.2650 - accuracy: 0.9013 - val_loss: 0.3038 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 109/10000\n",
      "113/113 [==============================] - 0s 832us/step - loss: 0.2648 - accuracy: 0.9013 - val_loss: 0.3036 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 110/10000\n",
      "113/113 [==============================] - 0s 808us/step - loss: 0.2646 - accuracy: 0.9013 - val_loss: 0.3035 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 111/10000\n",
      "113/113 [==============================] - 0s 787us/step - loss: 0.2644 - accuracy: 0.9013 - val_loss: 0.3033 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 112/10000\n",
      "113/113 [==============================] - 0s 771us/step - loss: 0.2643 - accuracy: 0.9013 - val_loss: 0.3031 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 113/10000\n",
      "113/113 [==============================] - 0s 783us/step - loss: 0.2641 - accuracy: 0.9013 - val_loss: 0.3029 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 114/10000\n",
      "113/113 [==============================] - 0s 767us/step - loss: 0.2639 - accuracy: 0.9004 - val_loss: 0.3028 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 115/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2637 - accuracy: 0.9013 - val_loss: 0.3026 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 116/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2635 - accuracy: 0.9013 - val_loss: 0.3024 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 117/10000\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.9004 - val_loss: 0.3023 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 118/10000\n",
      "113/113 [==============================] - 0s 819us/step - loss: 0.2632 - accuracy: 0.9004 - val_loss: 0.3021 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 119/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2630 - accuracy: 0.9004 - val_loss: 0.3020 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 120/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2628 - accuracy: 0.9004 - val_loss: 0.3018 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 121/10000\n",
      "113/113 [==============================] - 0s 774us/step - loss: 0.2626 - accuracy: 0.9004 - val_loss: 0.3017 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 122/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2625 - accuracy: 0.9004 - val_loss: 0.3015 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 123/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2623 - accuracy: 0.9013 - val_loss: 0.3014 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 124/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2621 - accuracy: 0.9013 - val_loss: 0.3012 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 125/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2620 - accuracy: 0.9013 - val_loss: 0.3011 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 126/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2618 - accuracy: 0.9013 - val_loss: 0.3010 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 127/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.2616 - accuracy: 0.9013 - val_loss: 0.3008 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 128/10000\n",
      "113/113 [==============================] - 0s 818us/step - loss: 0.2615 - accuracy: 0.9013 - val_loss: 0.3007 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 129/10000\n",
      "113/113 [==============================] - 0s 772us/step - loss: 0.2613 - accuracy: 0.9013 - val_loss: 0.3006 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 130/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2612 - accuracy: 0.9013 - val_loss: 0.3005 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 131/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2610 - accuracy: 0.9013 - val_loss: 0.3003 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 132/10000\n",
      "113/113 [==============================] - 0s 776us/step - loss: 0.2609 - accuracy: 0.9022 - val_loss: 0.3002 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 133/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2607 - accuracy: 0.9022 - val_loss: 0.3001 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 134/10000\n",
      "113/113 [==============================] - 0s 735us/step - loss: 0.2606 - accuracy: 0.9022 - val_loss: 0.3000 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 135/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.2604 - accuracy: 0.9022 - val_loss: 0.2999 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 136/10000\n",
      "113/113 [==============================] - 0s 736us/step - loss: 0.2603 - accuracy: 0.9022 - val_loss: 0.2998 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 137/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2601 - accuracy: 0.9022 - val_loss: 0.2996 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 138/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2600 - accuracy: 0.9022 - val_loss: 0.2995 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 139/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2598 - accuracy: 0.9022 - val_loss: 0.2994 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 140/10000\n",
      "113/113 [==============================] - 0s 805us/step - loss: 0.2597 - accuracy: 0.9022 - val_loss: 0.2993 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 141/10000\n",
      "113/113 [==============================] - 0s 728us/step - loss: 0.2595 - accuracy: 0.9022 - val_loss: 0.2992 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 142/10000\n",
      "113/113 [==============================] - 0s 724us/step - loss: 0.2594 - accuracy: 0.9022 - val_loss: 0.2991 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 143/10000\n",
      "113/113 [==============================] - 0s 808us/step - loss: 0.2593 - accuracy: 0.9022 - val_loss: 0.2990 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 144/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2591 - accuracy: 0.9022 - val_loss: 0.2989 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 145/10000\n",
      "113/113 [==============================] - 0s 824us/step - loss: 0.2590 - accuracy: 0.9031 - val_loss: 0.2988 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 146/10000\n",
      "113/113 [==============================] - 0s 782us/step - loss: 0.2588 - accuracy: 0.9031 - val_loss: 0.2987 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 147/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2587 - accuracy: 0.9031 - val_loss: 0.2986 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 148/10000\n",
      "113/113 [==============================] - 0s 777us/step - loss: 0.2586 - accuracy: 0.9031 - val_loss: 0.2985 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 761us/step - loss: 0.2584 - accuracy: 0.9031 - val_loss: 0.2984 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 150/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2583 - accuracy: 0.9031 - val_loss: 0.2984 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 151/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2582 - accuracy: 0.9031 - val_loss: 0.2983 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 152/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2580 - accuracy: 0.9031 - val_loss: 0.2982 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 153/10000\n",
      "113/113 [==============================] - 0s 776us/step - loss: 0.2579 - accuracy: 0.9031 - val_loss: 0.2981 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 154/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.2578 - accuracy: 0.9031 - val_loss: 0.2980 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 155/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2577 - accuracy: 0.9031 - val_loss: 0.2979 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 156/10000\n",
      "113/113 [==============================] - 0s 774us/step - loss: 0.2575 - accuracy: 0.9031 - val_loss: 0.2978 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 157/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2574 - accuracy: 0.9031 - val_loss: 0.2978 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 158/10000\n",
      "113/113 [==============================] - 0s 735us/step - loss: 0.2573 - accuracy: 0.9031 - val_loss: 0.2977 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 159/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2571 - accuracy: 0.9031 - val_loss: 0.2976 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 160/10000\n",
      "113/113 [==============================] - 0s 793us/step - loss: 0.2570 - accuracy: 0.9031 - val_loss: 0.2975 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 161/10000\n",
      "113/113 [==============================] - 0s 784us/step - loss: 0.2569 - accuracy: 0.9031 - val_loss: 0.2974 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 162/10000\n",
      "113/113 [==============================] - 0s 777us/step - loss: 0.2568 - accuracy: 0.9031 - val_loss: 0.2974 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 163/10000\n",
      "113/113 [==============================] - 0s 799us/step - loss: 0.2566 - accuracy: 0.9031 - val_loss: 0.2973 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 164/10000\n",
      "113/113 [==============================] - 0s 780us/step - loss: 0.2565 - accuracy: 0.9031 - val_loss: 0.2972 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 165/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2564 - accuracy: 0.9031 - val_loss: 0.2971 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 166/10000\n",
      "113/113 [==============================] - 0s 779us/step - loss: 0.2563 - accuracy: 0.9031 - val_loss: 0.2971 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 167/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.2562 - accuracy: 0.9031 - val_loss: 0.2970 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 168/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2560 - accuracy: 0.9031 - val_loss: 0.2969 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 169/10000\n",
      "113/113 [==============================] - 0s 795us/step - loss: 0.2559 - accuracy: 0.9031 - val_loss: 0.2968 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 170/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2558 - accuracy: 0.9031 - val_loss: 0.2968 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 171/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2557 - accuracy: 0.9031 - val_loss: 0.2967 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 172/10000\n",
      "113/113 [==============================] - 0s 798us/step - loss: 0.2556 - accuracy: 0.9031 - val_loss: 0.2966 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 173/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2554 - accuracy: 0.9040 - val_loss: 0.2966 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 174/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2553 - accuracy: 0.9040 - val_loss: 0.2965 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 175/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2552 - accuracy: 0.9040 - val_loss: 0.2964 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 176/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2551 - accuracy: 0.9040 - val_loss: 0.2964 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 177/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2550 - accuracy: 0.9049 - val_loss: 0.2963 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 178/10000\n",
      "113/113 [==============================] - 0s 736us/step - loss: 0.2549 - accuracy: 0.9049 - val_loss: 0.2962 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 179/10000\n",
      "113/113 [==============================] - 0s 733us/step - loss: 0.2548 - accuracy: 0.9049 - val_loss: 0.2962 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 180/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2546 - accuracy: 0.9049 - val_loss: 0.2961 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 181/10000\n",
      "113/113 [==============================] - 0s 831us/step - loss: 0.2545 - accuracy: 0.9058 - val_loss: 0.2961 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 182/10000\n",
      "113/113 [==============================] - 0s 786us/step - loss: 0.2544 - accuracy: 0.9058 - val_loss: 0.2960 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 183/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2543 - accuracy: 0.9058 - val_loss: 0.2959 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 184/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2542 - accuracy: 0.9058 - val_loss: 0.2959 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 185/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2541 - accuracy: 0.9067 - val_loss: 0.2958 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 186/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2540 - accuracy: 0.9076 - val_loss: 0.2958 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 187/10000\n",
      "113/113 [==============================] - 0s 730us/step - loss: 0.2539 - accuracy: 0.9076 - val_loss: 0.2957 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 188/10000\n",
      "113/113 [==============================] - 0s 731us/step - loss: 0.2537 - accuracy: 0.9076 - val_loss: 0.2956 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 189/10000\n",
      "113/113 [==============================] - 0s 725us/step - loss: 0.2536 - accuracy: 0.9076 - val_loss: 0.2956 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 190/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2535 - accuracy: 0.9076 - val_loss: 0.2955 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 191/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2534 - accuracy: 0.9076 - val_loss: 0.2955 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 192/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2533 - accuracy: 0.9076 - val_loss: 0.2954 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 193/10000\n",
      "113/113 [==============================] - 0s 737us/step - loss: 0.2532 - accuracy: 0.9076 - val_loss: 0.2954 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 194/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2531 - accuracy: 0.9076 - val_loss: 0.2953 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 195/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2530 - accuracy: 0.9076 - val_loss: 0.2952 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 196/10000\n",
      "113/113 [==============================] - 0s 733us/step - loss: 0.2529 - accuracy: 0.9076 - val_loss: 0.2952 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 197/10000\n",
      "113/113 [==============================] - 0s 772us/step - loss: 0.2528 - accuracy: 0.9076 - val_loss: 0.2951 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 198/10000\n",
      "113/113 [==============================] - 0s 766us/step - loss: 0.2527 - accuracy: 0.9076 - val_loss: 0.2951 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 199/10000\n",
      "113/113 [==============================] - 0s 790us/step - loss: 0.2526 - accuracy: 0.9076 - val_loss: 0.2950 - val_accuracy: 0.8720 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/10000\n",
      "113/113 [==============================] - 0s 921us/step - loss: 0.2525 - accuracy: 0.9076 - val_loss: 0.2950 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 201/10000\n",
      "113/113 [==============================] - 0s 779us/step - loss: 0.2523 - accuracy: 0.9076 - val_loss: 0.2949 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 202/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2522 - accuracy: 0.9084 - val_loss: 0.2949 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 203/10000\n",
      "113/113 [==============================] - 0s 768us/step - loss: 0.2521 - accuracy: 0.9084 - val_loss: 0.2948 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 204/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2520 - accuracy: 0.9084 - val_loss: 0.2948 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 205/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2519 - accuracy: 0.9084 - val_loss: 0.2947 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 206/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2518 - accuracy: 0.9076 - val_loss: 0.2947 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 207/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2517 - accuracy: 0.9076 - val_loss: 0.2946 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 208/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2516 - accuracy: 0.9076 - val_loss: 0.2946 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 209/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2515 - accuracy: 0.9076 - val_loss: 0.2945 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 210/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2514 - accuracy: 0.9067 - val_loss: 0.2945 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 211/10000\n",
      "113/113 [==============================] - 0s 771us/step - loss: 0.2513 - accuracy: 0.9067 - val_loss: 0.2944 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 212/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2512 - accuracy: 0.9067 - val_loss: 0.2944 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 213/10000\n",
      "113/113 [==============================] - 0s 777us/step - loss: 0.2511 - accuracy: 0.9067 - val_loss: 0.2943 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 214/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2510 - accuracy: 0.9067 - val_loss: 0.2943 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 215/10000\n",
      "113/113 [==============================] - 0s 766us/step - loss: 0.2509 - accuracy: 0.9067 - val_loss: 0.2942 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 216/10000\n",
      "113/113 [==============================] - 0s 772us/step - loss: 0.2508 - accuracy: 0.9067 - val_loss: 0.2942 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 217/10000\n",
      "113/113 [==============================] - 0s 805us/step - loss: 0.2507 - accuracy: 0.9067 - val_loss: 0.2941 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 218/10000\n",
      "113/113 [==============================] - 0s 863us/step - loss: 0.2506 - accuracy: 0.9067 - val_loss: 0.2941 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 219/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2505 - accuracy: 0.9067 - val_loss: 0.2940 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 220/10000\n",
      "113/113 [==============================] - 0s 795us/step - loss: 0.2504 - accuracy: 0.9067 - val_loss: 0.2940 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 221/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2503 - accuracy: 0.9067 - val_loss: 0.2939 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 222/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2502 - accuracy: 0.9067 - val_loss: 0.2939 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 223/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2501 - accuracy: 0.9067 - val_loss: 0.2938 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 224/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2500 - accuracy: 0.9067 - val_loss: 0.2938 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 225/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2499 - accuracy: 0.9067 - val_loss: 0.2937 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 226/10000\n",
      "113/113 [==============================] - 0s 778us/step - loss: 0.2498 - accuracy: 0.9067 - val_loss: 0.2937 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 227/10000\n",
      "113/113 [==============================] - 0s 783us/step - loss: 0.2497 - accuracy: 0.9067 - val_loss: 0.2936 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 228/10000\n",
      "113/113 [==============================] - 0s 830us/step - loss: 0.2496 - accuracy: 0.9067 - val_loss: 0.2936 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 229/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2495 - accuracy: 0.9067 - val_loss: 0.2935 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 230/10000\n",
      "113/113 [==============================] - 0s 766us/step - loss: 0.2494 - accuracy: 0.9067 - val_loss: 0.2935 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 231/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2493 - accuracy: 0.9067 - val_loss: 0.2934 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 232/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2492 - accuracy: 0.9067 - val_loss: 0.2934 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 233/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2491 - accuracy: 0.9067 - val_loss: 0.2933 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 234/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2490 - accuracy: 0.9067 - val_loss: 0.2933 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 235/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2489 - accuracy: 0.9058 - val_loss: 0.2933 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 236/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2488 - accuracy: 0.9058 - val_loss: 0.2932 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 237/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2487 - accuracy: 0.9058 - val_loss: 0.2932 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 238/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2486 - accuracy: 0.9058 - val_loss: 0.2931 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 239/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2485 - accuracy: 0.9058 - val_loss: 0.2931 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 240/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2484 - accuracy: 0.9058 - val_loss: 0.2930 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 241/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2483 - accuracy: 0.9058 - val_loss: 0.2930 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 242/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2482 - accuracy: 0.9058 - val_loss: 0.2929 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 243/10000\n",
      "113/113 [==============================] - 0s 725us/step - loss: 0.2482 - accuracy: 0.9058 - val_loss: 0.2929 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 244/10000\n",
      "113/113 [==============================] - 0s 806us/step - loss: 0.2481 - accuracy: 0.9058 - val_loss: 0.2928 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 245/10000\n",
      "113/113 [==============================] - 0s 837us/step - loss: 0.2480 - accuracy: 0.9058 - val_loss: 0.2928 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 246/10000\n",
      "113/113 [==============================] - 0s 763us/step - loss: 0.2479 - accuracy: 0.9058 - val_loss: 0.2928 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 247/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2478 - accuracy: 0.9058 - val_loss: 0.2927 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 248/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2477 - accuracy: 0.9058 - val_loss: 0.2927 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 249/10000\n",
      "113/113 [==============================] - 0s 777us/step - loss: 0.2476 - accuracy: 0.9058 - val_loss: 0.2926 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 250/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 759us/step - loss: 0.2475 - accuracy: 0.9058 - val_loss: 0.2926 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 251/10000\n",
      "113/113 [==============================] - 0s 736us/step - loss: 0.2474 - accuracy: 0.9058 - val_loss: 0.2925 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 252/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2473 - accuracy: 0.9067 - val_loss: 0.2925 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 253/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2472 - accuracy: 0.9067 - val_loss: 0.2924 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 254/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2471 - accuracy: 0.9067 - val_loss: 0.2924 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 255/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2470 - accuracy: 0.9067 - val_loss: 0.2923 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 256/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2469 - accuracy: 0.9067 - val_loss: 0.2923 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 257/10000\n",
      "113/113 [==============================] - 0s 731us/step - loss: 0.2468 - accuracy: 0.9067 - val_loss: 0.2923 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 258/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.2467 - accuracy: 0.9067 - val_loss: 0.2922 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 259/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2467 - accuracy: 0.9067 - val_loss: 0.2922 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 260/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2466 - accuracy: 0.9067 - val_loss: 0.2921 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 261/10000\n",
      "113/113 [==============================] - 0s 795us/step - loss: 0.2465 - accuracy: 0.9067 - val_loss: 0.2921 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 262/10000\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.9067 - val_loss: 0.2920 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 263/10000\n",
      "113/113 [==============================] - 0s 826us/step - loss: 0.2463 - accuracy: 0.9076 - val_loss: 0.2920 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 264/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2462 - accuracy: 0.9076 - val_loss: 0.2920 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 265/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2461 - accuracy: 0.9076 - val_loss: 0.2919 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 266/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2460 - accuracy: 0.9076 - val_loss: 0.2919 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 267/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2459 - accuracy: 0.9076 - val_loss: 0.2918 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 268/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2458 - accuracy: 0.9076 - val_loss: 0.2918 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 269/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2457 - accuracy: 0.9076 - val_loss: 0.2917 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 270/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2457 - accuracy: 0.9076 - val_loss: 0.2917 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 271/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2456 - accuracy: 0.9076 - val_loss: 0.2916 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 272/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2455 - accuracy: 0.9076 - val_loss: 0.2916 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 273/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2454 - accuracy: 0.9076 - val_loss: 0.2916 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 274/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2453 - accuracy: 0.9076 - val_loss: 0.2915 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 275/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2452 - accuracy: 0.9076 - val_loss: 0.2915 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 276/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.2451 - accuracy: 0.9076 - val_loss: 0.2914 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 277/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2450 - accuracy: 0.9076 - val_loss: 0.2914 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 278/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2449 - accuracy: 0.9076 - val_loss: 0.2914 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 279/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2449 - accuracy: 0.9076 - val_loss: 0.2913 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 280/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2448 - accuracy: 0.9076 - val_loss: 0.2913 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 281/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2447 - accuracy: 0.9076 - val_loss: 0.2912 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 282/10000\n",
      "113/113 [==============================] - 0s 727us/step - loss: 0.2446 - accuracy: 0.9076 - val_loss: 0.2912 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 283/10000\n",
      "113/113 [==============================] - 0s 768us/step - loss: 0.2445 - accuracy: 0.9076 - val_loss: 0.2911 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 284/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2444 - accuracy: 0.9084 - val_loss: 0.2911 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 285/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2443 - accuracy: 0.9093 - val_loss: 0.2911 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 286/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2442 - accuracy: 0.9093 - val_loss: 0.2910 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 287/10000\n",
      "113/113 [==============================] - 0s 736us/step - loss: 0.2442 - accuracy: 0.9093 - val_loss: 0.2910 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 288/10000\n",
      "113/113 [==============================] - 0s 736us/step - loss: 0.2441 - accuracy: 0.9093 - val_loss: 0.2909 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 289/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2440 - accuracy: 0.9093 - val_loss: 0.2909 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 290/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2439 - accuracy: 0.9093 - val_loss: 0.2909 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 291/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2438 - accuracy: 0.9093 - val_loss: 0.2908 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 292/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2437 - accuracy: 0.9093 - val_loss: 0.2908 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 293/10000\n",
      "113/113 [==============================] - 0s 723us/step - loss: 0.2436 - accuracy: 0.9093 - val_loss: 0.2907 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 294/10000\n",
      "113/113 [==============================] - 0s 763us/step - loss: 0.2436 - accuracy: 0.9093 - val_loss: 0.2907 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 295/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2435 - accuracy: 0.9093 - val_loss: 0.2907 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 296/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.2434 - accuracy: 0.9093 - val_loss: 0.2906 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 297/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2433 - accuracy: 0.9093 - val_loss: 0.2906 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 298/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2432 - accuracy: 0.9093 - val_loss: 0.2905 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 299/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2431 - accuracy: 0.9093 - val_loss: 0.2905 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 300/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2431 - accuracy: 0.9093 - val_loss: 0.2905 - val_accuracy: 0.8720 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2430 - accuracy: 0.9093 - val_loss: 0.2904 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 302/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.2429 - accuracy: 0.9093 - val_loss: 0.2904 - val_accuracy: 0.8720 - lr: 0.0010\n",
      "Epoch 303/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2428 - accuracy: 0.9093 - val_loss: 0.2904 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 304/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2427 - accuracy: 0.9093 - val_loss: 0.2903 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 305/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.2426 - accuracy: 0.9093 - val_loss: 0.2903 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 306/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2426 - accuracy: 0.9093 - val_loss: 0.2902 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 307/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2425 - accuracy: 0.9093 - val_loss: 0.2902 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 308/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2424 - accuracy: 0.9093 - val_loss: 0.2902 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 309/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2423 - accuracy: 0.9093 - val_loss: 0.2901 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 310/10000\n",
      "113/113 [==============================] - 0s 778us/step - loss: 0.2422 - accuracy: 0.9093 - val_loss: 0.2901 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 311/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2422 - accuracy: 0.9093 - val_loss: 0.2901 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 312/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2421 - accuracy: 0.9093 - val_loss: 0.2900 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 313/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2420 - accuracy: 0.9093 - val_loss: 0.2900 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 314/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2419 - accuracy: 0.9093 - val_loss: 0.2900 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 315/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2418 - accuracy: 0.9093 - val_loss: 0.2899 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 316/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2417 - accuracy: 0.9093 - val_loss: 0.2899 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 317/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2417 - accuracy: 0.9093 - val_loss: 0.2898 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 318/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2416 - accuracy: 0.9093 - val_loss: 0.2898 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 319/10000\n",
      "113/113 [==============================] - 0s 773us/step - loss: 0.2415 - accuracy: 0.9093 - val_loss: 0.2898 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 320/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2414 - accuracy: 0.9093 - val_loss: 0.2897 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 321/10000\n",
      "113/113 [==============================] - 0s 732us/step - loss: 0.2413 - accuracy: 0.9093 - val_loss: 0.2897 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 322/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2413 - accuracy: 0.9093 - val_loss: 0.2897 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 323/10000\n",
      "113/113 [==============================] - 0s 792us/step - loss: 0.2412 - accuracy: 0.9093 - val_loss: 0.2896 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 324/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2411 - accuracy: 0.9102 - val_loss: 0.2896 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 325/10000\n",
      "113/113 [==============================] - 0s 772us/step - loss: 0.2410 - accuracy: 0.9102 - val_loss: 0.2896 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 326/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2410 - accuracy: 0.9102 - val_loss: 0.2895 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 327/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2409 - accuracy: 0.9102 - val_loss: 0.2895 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 328/10000\n",
      "113/113 [==============================] - 0s 773us/step - loss: 0.2408 - accuracy: 0.9102 - val_loss: 0.2895 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 329/10000\n",
      "113/113 [==============================] - 0s 782us/step - loss: 0.2407 - accuracy: 0.9102 - val_loss: 0.2895 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 330/10000\n",
      "113/113 [==============================] - 0s 772us/step - loss: 0.2406 - accuracy: 0.9102 - val_loss: 0.2894 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 331/10000\n",
      "113/113 [==============================] - 0s 766us/step - loss: 0.2406 - accuracy: 0.9102 - val_loss: 0.2894 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 332/10000\n",
      "113/113 [==============================] - 0s 809us/step - loss: 0.2405 - accuracy: 0.9102 - val_loss: 0.2894 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 333/10000\n",
      "113/113 [==============================] - 0s 872us/step - loss: 0.2404 - accuracy: 0.9102 - val_loss: 0.2893 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 334/10000\n",
      "113/113 [==============================] - 0s 947us/step - loss: 0.2403 - accuracy: 0.9102 - val_loss: 0.2893 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 335/10000\n",
      "113/113 [==============================] - 0s 869us/step - loss: 0.2403 - accuracy: 0.9102 - val_loss: 0.2893 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 336/10000\n",
      "113/113 [==============================] - 0s 839us/step - loss: 0.2402 - accuracy: 0.9102 - val_loss: 0.2892 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 337/10000\n",
      "113/113 [==============================] - 0s 815us/step - loss: 0.2401 - accuracy: 0.9102 - val_loss: 0.2892 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 338/10000\n",
      "113/113 [==============================] - 0s 823us/step - loss: 0.2400 - accuracy: 0.9102 - val_loss: 0.2892 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 339/10000\n",
      "113/113 [==============================] - 0s 918us/step - loss: 0.2400 - accuracy: 0.9102 - val_loss: 0.2891 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 340/10000\n",
      "113/113 [==============================] - 0s 825us/step - loss: 0.2399 - accuracy: 0.9102 - val_loss: 0.2891 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 341/10000\n",
      "113/113 [==============================] - 0s 808us/step - loss: 0.2398 - accuracy: 0.9102 - val_loss: 0.2891 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 342/10000\n",
      "113/113 [==============================] - 0s 816us/step - loss: 0.2397 - accuracy: 0.9102 - val_loss: 0.2891 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 343/10000\n",
      "113/113 [==============================] - 0s 809us/step - loss: 0.2397 - accuracy: 0.9102 - val_loss: 0.2890 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 344/10000\n",
      "113/113 [==============================] - 0s 802us/step - loss: 0.2396 - accuracy: 0.9102 - val_loss: 0.2890 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 345/10000\n",
      "113/113 [==============================] - 0s 805us/step - loss: 0.2395 - accuracy: 0.9102 - val_loss: 0.2890 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 346/10000\n",
      "113/113 [==============================] - 0s 803us/step - loss: 0.2394 - accuracy: 0.9102 - val_loss: 0.2889 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 347/10000\n",
      "113/113 [==============================] - 0s 806us/step - loss: 0.2394 - accuracy: 0.9102 - val_loss: 0.2889 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 348/10000\n",
      "113/113 [==============================] - 0s 799us/step - loss: 0.2393 - accuracy: 0.9102 - val_loss: 0.2889 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 349/10000\n",
      "113/113 [==============================] - 0s 808us/step - loss: 0.2392 - accuracy: 0.9102 - val_loss: 0.2889 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 350/10000\n",
      "113/113 [==============================] - 0s 811us/step - loss: 0.2391 - accuracy: 0.9102 - val_loss: 0.2888 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 351/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 814us/step - loss: 0.2391 - accuracy: 0.9102 - val_loss: 0.2888 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 352/10000\n",
      "113/113 [==============================] - 0s 825us/step - loss: 0.2390 - accuracy: 0.9102 - val_loss: 0.2888 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 353/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2389 - accuracy: 0.9102 - val_loss: 0.2888 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 354/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2389 - accuracy: 0.9102 - val_loss: 0.2887 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 355/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.2388 - accuracy: 0.9102 - val_loss: 0.2887 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 356/10000\n",
      "113/113 [==============================] - 0s 711us/step - loss: 0.2387 - accuracy: 0.9102 - val_loss: 0.2887 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 357/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2386 - accuracy: 0.9102 - val_loss: 0.2887 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 358/10000\n",
      "113/113 [==============================] - 0s 727us/step - loss: 0.2386 - accuracy: 0.9102 - val_loss: 0.2886 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 359/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2385 - accuracy: 0.9102 - val_loss: 0.2886 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 360/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2384 - accuracy: 0.9102 - val_loss: 0.2886 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 361/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2384 - accuracy: 0.9102 - val_loss: 0.2886 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 362/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2383 - accuracy: 0.9102 - val_loss: 0.2885 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 363/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2382 - accuracy: 0.9102 - val_loss: 0.2885 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 364/10000\n",
      "113/113 [==============================] - 0s 786us/step - loss: 0.2381 - accuracy: 0.9102 - val_loss: 0.2885 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 365/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2381 - accuracy: 0.9102 - val_loss: 0.2885 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 366/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2380 - accuracy: 0.9102 - val_loss: 0.2884 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 367/10000\n",
      "113/113 [==============================] - 0s 732us/step - loss: 0.2379 - accuracy: 0.9102 - val_loss: 0.2884 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 368/10000\n",
      "113/113 [==============================] - 0s 735us/step - loss: 0.2379 - accuracy: 0.9102 - val_loss: 0.2884 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 369/10000\n",
      "113/113 [==============================] - 0s 731us/step - loss: 0.2378 - accuracy: 0.9102 - val_loss: 0.2884 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 370/10000\n",
      "113/113 [==============================] - 0s 733us/step - loss: 0.2377 - accuracy: 0.9102 - val_loss: 0.2884 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 371/10000\n",
      "113/113 [==============================] - 0s 735us/step - loss: 0.2376 - accuracy: 0.9102 - val_loss: 0.2883 - val_accuracy: 0.8640 - lr: 0.0010\n",
      "Epoch 372/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2376 - accuracy: 0.9102 - val_loss: 0.2883 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 373/10000\n",
      "113/113 [==============================] - 0s 737us/step - loss: 0.2375 - accuracy: 0.9102 - val_loss: 0.2883 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 374/10000\n",
      "113/113 [==============================] - 0s 763us/step - loss: 0.2374 - accuracy: 0.9102 - val_loss: 0.2883 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 375/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2374 - accuracy: 0.9102 - val_loss: 0.2882 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 376/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2373 - accuracy: 0.9102 - val_loss: 0.2882 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 377/10000\n",
      "113/113 [==============================] - 0s 739us/step - loss: 0.2372 - accuracy: 0.9102 - val_loss: 0.2882 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 378/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.2372 - accuracy: 0.9102 - val_loss: 0.2882 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 379/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2371 - accuracy: 0.9111 - val_loss: 0.2882 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 380/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2370 - accuracy: 0.9111 - val_loss: 0.2881 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 381/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2370 - accuracy: 0.9111 - val_loss: 0.2881 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 382/10000\n",
      "113/113 [==============================] - 0s 736us/step - loss: 0.2369 - accuracy: 0.9111 - val_loss: 0.2881 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 383/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2368 - accuracy: 0.9111 - val_loss: 0.2881 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 384/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2365 - accuracy: 0.9111 - val_loss: 0.2878 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 385/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2365 - accuracy: 0.9111 - val_loss: 0.2878 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 386/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2364 - accuracy: 0.9102 - val_loss: 0.2878 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 387/10000\n",
      "113/113 [==============================] - 0s 733us/step - loss: 0.2363 - accuracy: 0.9102 - val_loss: 0.2878 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 388/10000\n",
      "113/113 [==============================] - 0s 731us/step - loss: 0.2363 - accuracy: 0.9102 - val_loss: 0.2878 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 389/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2362 - accuracy: 0.9102 - val_loss: 0.2877 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 390/10000\n",
      "113/113 [==============================] - 0s 800us/step - loss: 0.2360 - accuracy: 0.9102 - val_loss: 0.2874 - val_accuracy: 0.8693 - lr: 6.4000e-04\n",
      "Epoch 391/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2359 - accuracy: 0.9102 - val_loss: 0.2874 - val_accuracy: 0.8693 - lr: 6.4000e-04\n",
      "Epoch 392/10000\n",
      "113/113 [==============================] - 0s 726us/step - loss: 0.2359 - accuracy: 0.9102 - val_loss: 0.2874 - val_accuracy: 0.8693 - lr: 6.4000e-04\n",
      "Epoch 393/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2358 - accuracy: 0.9102 - val_loss: 0.2874 - val_accuracy: 0.8693 - lr: 6.4000e-04\n",
      "Epoch 394/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2358 - accuracy: 0.9102 - val_loss: 0.2874 - val_accuracy: 0.8693 - lr: 6.4000e-04\n",
      "Epoch 395/10000\n",
      "113/113 [==============================] - 0s 763us/step - loss: 0.2358 - accuracy: 0.9111 - val_loss: 0.2874 - val_accuracy: 0.8693 - lr: 6.4000e-04\n",
      "Epoch 396/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2356 - accuracy: 0.9102 - val_loss: 0.2871 - val_accuracy: 0.8693 - lr: 5.1200e-04\n",
      "Epoch 397/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2355 - accuracy: 0.9111 - val_loss: 0.2871 - val_accuracy: 0.8693 - lr: 5.1200e-04\n",
      "Epoch 398/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2355 - accuracy: 0.9111 - val_loss: 0.2871 - val_accuracy: 0.8693 - lr: 5.1200e-04\n",
      "Epoch 399/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2354 - accuracy: 0.9111 - val_loss: 0.2871 - val_accuracy: 0.8693 - lr: 5.1200e-04\n",
      "Epoch 400/10000\n",
      "113/113 [==============================] - 0s 778us/step - loss: 0.2354 - accuracy: 0.9111 - val_loss: 0.2871 - val_accuracy: 0.8693 - lr: 5.1200e-04\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 789us/step - loss: 0.2354 - accuracy: 0.9111 - val_loss: 0.2871 - val_accuracy: 0.8693 - lr: 5.1200e-04\n",
      "Epoch 402/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2352 - accuracy: 0.9111 - val_loss: 0.2868 - val_accuracy: 0.8720 - lr: 4.0960e-04\n",
      "Epoch 403/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2351 - accuracy: 0.9111 - val_loss: 0.2868 - val_accuracy: 0.8720 - lr: 4.0960e-04\n",
      "Epoch 404/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2351 - accuracy: 0.9111 - val_loss: 0.2868 - val_accuracy: 0.8720 - lr: 4.0960e-04\n",
      "Epoch 405/10000\n",
      "113/113 [==============================] - 0s 880us/step - loss: 0.2351 - accuracy: 0.9111 - val_loss: 0.2868 - val_accuracy: 0.8720 - lr: 4.0960e-04\n",
      "Epoch 406/10000\n",
      "113/113 [==============================] - 0s 782us/step - loss: 0.2351 - accuracy: 0.9111 - val_loss: 0.2868 - val_accuracy: 0.8720 - lr: 4.0960e-04\n",
      "Epoch 407/10000\n",
      "113/113 [==============================] - 0s 773us/step - loss: 0.2350 - accuracy: 0.9111 - val_loss: 0.2868 - val_accuracy: 0.8720 - lr: 4.0960e-04\n",
      "Epoch 408/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2349 - accuracy: 0.9111 - val_loss: 0.2866 - val_accuracy: 0.8747 - lr: 3.2768e-04\n",
      "Epoch 409/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2349 - accuracy: 0.9102 - val_loss: 0.2866 - val_accuracy: 0.8773 - lr: 3.2768e-04\n",
      "Epoch 410/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2348 - accuracy: 0.9102 - val_loss: 0.2866 - val_accuracy: 0.8773 - lr: 3.2768e-04\n",
      "Epoch 411/10000\n",
      "113/113 [==============================] - 0s 737us/step - loss: 0.2348 - accuracy: 0.9102 - val_loss: 0.2866 - val_accuracy: 0.8773 - lr: 3.2768e-04\n",
      "Epoch 412/10000\n",
      "113/113 [==============================] - 0s 729us/step - loss: 0.2348 - accuracy: 0.9102 - val_loss: 0.2866 - val_accuracy: 0.8773 - lr: 3.2768e-04\n",
      "Epoch 413/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2348 - accuracy: 0.9102 - val_loss: 0.2866 - val_accuracy: 0.8773 - lr: 3.2768e-04\n",
      "Epoch 414/10000\n",
      "113/113 [==============================] - 0s 808us/step - loss: 0.2347 - accuracy: 0.9102 - val_loss: 0.2865 - val_accuracy: 0.8800 - lr: 2.6214e-04\n",
      "Epoch 415/10000\n",
      "113/113 [==============================] - 0s 894us/step - loss: 0.2346 - accuracy: 0.9102 - val_loss: 0.2865 - val_accuracy: 0.8800 - lr: 2.6214e-04\n",
      "Epoch 416/10000\n",
      "113/113 [==============================] - 0s 850us/step - loss: 0.2346 - accuracy: 0.9102 - val_loss: 0.2864 - val_accuracy: 0.8800 - lr: 2.6214e-04\n",
      "Epoch 417/10000\n",
      "113/113 [==============================] - 0s 819us/step - loss: 0.2346 - accuracy: 0.9102 - val_loss: 0.2864 - val_accuracy: 0.8800 - lr: 2.6214e-04\n",
      "Epoch 418/10000\n",
      "113/113 [==============================] - 0s 878us/step - loss: 0.2346 - accuracy: 0.9102 - val_loss: 0.2864 - val_accuracy: 0.8800 - lr: 2.6214e-04\n",
      "Epoch 419/10000\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2346 - accuracy: 0.9102 - val_loss: 0.2864 - val_accuracy: 0.8800 - lr: 2.6214e-04\n",
      "Epoch 420/10000\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.9102 - val_loss: 0.2864 - val_accuracy: 0.8800 - lr: 2.0972e-04\n",
      "Epoch 421/10000\n",
      "113/113 [==============================] - 0s 832us/step - loss: 0.2344 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 2.0972e-04\n",
      "Epoch 422/10000\n",
      "113/113 [==============================] - 0s 820us/step - loss: 0.2344 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 2.0972e-04\n",
      "Epoch 423/10000\n",
      "113/113 [==============================] - 0s 780us/step - loss: 0.2344 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 2.0972e-04\n",
      "Epoch 424/10000\n",
      "113/113 [==============================] - 0s 830us/step - loss: 0.2344 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 2.0972e-04\n",
      "Epoch 425/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2344 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 2.0972e-04\n",
      "Epoch 426/10000\n",
      "113/113 [==============================] - 0s 766us/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 427/10000\n",
      "113/113 [==============================] - 0s 773us/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.2863 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 428/10000\n",
      "113/113 [==============================] - 0s 791us/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 429/10000\n",
      "113/113 [==============================] - 0s 768us/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 430/10000\n",
      "113/113 [==============================] - 0s 787us/step - loss: 0.2343 - accuracy: 0.9102 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 431/10000\n",
      "113/113 [==============================] - 0s 801us/step - loss: 0.2342 - accuracy: 0.9102 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 432/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2342 - accuracy: 0.9102 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.6777e-04\n",
      "Epoch 433/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2342 - accuracy: 0.9102 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.3422e-04\n",
      "Epoch 434/10000\n",
      "113/113 [==============================] - 0s 774us/step - loss: 0.2342 - accuracy: 0.9111 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.3422e-04\n",
      "Epoch 435/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.3422e-04\n",
      "Epoch 436/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.3422e-04\n",
      "Epoch 437/10000\n",
      "113/113 [==============================] - 0s 769us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.3422e-04\n",
      "Epoch 438/10000\n",
      "113/113 [==============================] - 0s 791us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2862 - val_accuracy: 0.8800 - lr: 1.0737e-04\n",
      "Epoch 439/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 1.0737e-04\n",
      "Epoch 440/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 1.0737e-04\n",
      "Epoch 441/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 1.0737e-04\n",
      "Epoch 442/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 1.0737e-04\n",
      "Epoch 443/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 1.0737e-04\n",
      "Epoch 444/10000\n",
      "113/113 [==============================] - 0s 730us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 8.5899e-05\n",
      "Epoch 445/10000\n",
      "113/113 [==============================] - 0s 765us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 8.5899e-05\n",
      "Epoch 446/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 8.5899e-05\n",
      "Epoch 447/10000\n",
      "113/113 [==============================] - 0s 762us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 8.5899e-05\n",
      "Epoch 448/10000\n",
      "113/113 [==============================] - 0s 749us/step - loss: 0.2340 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 8.5899e-05\n",
      "Epoch 449/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 6.8719e-05\n",
      "Epoch 450/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 728us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 6.8719e-05\n",
      "Epoch 451/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 6.8719e-05\n",
      "Epoch 452/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 6.8719e-05\n",
      "Epoch 453/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 6.8719e-05\n",
      "Epoch 454/10000\n",
      "113/113 [==============================] - 0s 761us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 455/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2861 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 456/10000\n",
      "113/113 [==============================] - 0s 727us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 457/10000\n",
      "113/113 [==============================] - 0s 733us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 458/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 459/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 460/10000\n",
      "113/113 [==============================] - 0s 725us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.4976e-05\n",
      "Epoch 461/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.3980e-05\n",
      "Epoch 462/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2339 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.3980e-05\n",
      "Epoch 463/10000\n",
      "113/113 [==============================] - 0s 744us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.3980e-05\n",
      "Epoch 464/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.3980e-05\n",
      "Epoch 465/10000\n",
      "113/113 [==============================] - 0s 758us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.3980e-05\n",
      "Epoch 466/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.5184e-05\n",
      "Epoch 467/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.5184e-05\n",
      "Epoch 468/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.5184e-05\n",
      "Epoch 469/10000\n",
      "113/113 [==============================] - 0s 728us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.5184e-05\n",
      "Epoch 470/10000\n",
      "113/113 [==============================] - 0s 766us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.5184e-05\n",
      "Epoch 471/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.8147e-05\n",
      "Epoch 472/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.8147e-05\n",
      "Epoch 473/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.8147e-05\n",
      "Epoch 474/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.8147e-05\n",
      "Epoch 475/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.8147e-05\n",
      "Epoch 476/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.2518e-05\n",
      "Epoch 477/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.2518e-05\n",
      "Epoch 478/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.2518e-05\n",
      "Epoch 479/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.2518e-05\n",
      "Epoch 480/10000\n",
      "113/113 [==============================] - 0s 788us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.2518e-05\n",
      "Epoch 481/10000\n",
      "113/113 [==============================] - 0s 773us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.8014e-05\n",
      "Epoch 482/10000\n",
      "113/113 [==============================] - 0s 789us/step - loss: 0.2338 - accuracy: 0.9111 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.8014e-05\n",
      "Epoch 483/10000\n",
      "113/113 [==============================] - 0s 883us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.8014e-05\n",
      "Epoch 484/10000\n",
      "113/113 [==============================] - 0s 935us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.8014e-05\n",
      "Epoch 485/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.8014e-05\n",
      "Epoch 486/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.4412e-05\n",
      "Epoch 487/10000\n",
      "113/113 [==============================] - 0s 784us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.4412e-05\n",
      "Epoch 488/10000\n",
      "113/113 [==============================] - 0s 817us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.4412e-05\n",
      "Epoch 489/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.4412e-05\n",
      "Epoch 490/10000\n",
      "113/113 [==============================] - 0s 734us/step - loss: 0.2338 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.4412e-05\n",
      "Epoch 491/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.1529e-05\n",
      "Epoch 492/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.1529e-05\n",
      "Epoch 493/10000\n",
      "113/113 [==============================] - 0s 721us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.1529e-05\n",
      "Epoch 494/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.1529e-05\n",
      "Epoch 495/10000\n",
      "113/113 [==============================] - 0s 737us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.1529e-05\n",
      "Epoch 496/10000\n",
      "113/113 [==============================] - 0s 756us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.2234e-06\n",
      "Epoch 497/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.2234e-06\n",
      "Epoch 498/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.2234e-06\n",
      "Epoch 499/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 776us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.2234e-06\n",
      "Epoch 500/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.2234e-06\n",
      "Epoch 501/10000\n",
      "113/113 [==============================] - 0s 721us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.3787e-06\n",
      "Epoch 502/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.3787e-06\n",
      "Epoch 503/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.3787e-06\n",
      "Epoch 504/10000\n",
      "113/113 [==============================] - 0s 747us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.3787e-06\n",
      "Epoch 505/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.3787e-06\n",
      "Epoch 506/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.9030e-06\n",
      "Epoch 507/10000\n",
      "113/113 [==============================] - 0s 735us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.9030e-06\n",
      "Epoch 508/10000\n",
      "113/113 [==============================] - 0s 726us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.9030e-06\n",
      "Epoch 509/10000\n",
      "113/113 [==============================] - 0s 738us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.9030e-06\n",
      "Epoch 510/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 5.9030e-06\n",
      "Epoch 511/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.7224e-06\n",
      "Epoch 512/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.7224e-06\n",
      "Epoch 513/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.7224e-06\n",
      "Epoch 514/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.7224e-06\n",
      "Epoch 515/10000\n",
      "113/113 [==============================] - 0s 789us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 4.7224e-06\n",
      "Epoch 516/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.7779e-06\n",
      "Epoch 517/10000\n",
      "113/113 [==============================] - 0s 746us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.7779e-06\n",
      "Epoch 518/10000\n",
      "113/113 [==============================] - 0s 745us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.7779e-06\n",
      "Epoch 519/10000\n",
      "113/113 [==============================] - 0s 757us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.7779e-06\n",
      "Epoch 520/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.7779e-06\n",
      "Epoch 521/10000\n",
      "113/113 [==============================] - 0s 750us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.0223e-06\n",
      "Epoch 522/10000\n",
      "113/113 [==============================] - 0s 720us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.0223e-06\n",
      "Epoch 523/10000\n",
      "113/113 [==============================] - 0s 748us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.0223e-06\n",
      "Epoch 524/10000\n",
      "113/113 [==============================] - 0s 743us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.0223e-06\n",
      "Epoch 525/10000\n",
      "113/113 [==============================] - 0s 740us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 3.0223e-06\n",
      "Epoch 526/10000\n",
      "113/113 [==============================] - 0s 759us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.4179e-06\n",
      "Epoch 527/10000\n",
      "113/113 [==============================] - 0s 731us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.4179e-06\n",
      "Epoch 528/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.4179e-06\n",
      "Epoch 529/10000\n",
      "113/113 [==============================] - 0s 753us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.4179e-06\n",
      "Epoch 530/10000\n",
      "113/113 [==============================] - 0s 790us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 2.4179e-06\n",
      "Epoch 531/10000\n",
      "113/113 [==============================] - 0s 781us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.9343e-06\n",
      "Epoch 532/10000\n",
      "113/113 [==============================] - 0s 767us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.9343e-06\n",
      "Epoch 533/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.9343e-06\n",
      "Epoch 534/10000\n",
      "113/113 [==============================] - 0s 755us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.9343e-06\n",
      "Epoch 535/10000\n",
      "113/113 [==============================] - 0s 742us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.9343e-06\n",
      "Epoch 536/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.5474e-06\n",
      "Epoch 537/10000\n",
      "113/113 [==============================] - 0s 741us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.5474e-06\n",
      "Epoch 538/10000\n",
      "113/113 [==============================] - 0s 760us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.5474e-06\n",
      "Epoch 539/10000\n",
      "113/113 [==============================] - 0s 773us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.5474e-06\n",
      "Epoch 540/10000\n",
      "113/113 [==============================] - 0s 819us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.5474e-06\n",
      "Epoch 541/10000\n",
      "113/113 [==============================] - 0s 784us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.2379e-06\n",
      "Epoch 542/10000\n",
      "113/113 [==============================] - 0s 784us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.2379e-06\n",
      "Epoch 543/10000\n",
      "113/113 [==============================] - 0s 800us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.2379e-06\n",
      "Epoch 544/10000\n",
      "113/113 [==============================] - 0s 780us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.2379e-06\n",
      "Epoch 545/10000\n",
      "113/113 [==============================] - 0s 764us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 1.2379e-06\n",
      "Epoch 546/10000\n",
      "113/113 [==============================] - 0s 751us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.9035e-07\n",
      "Epoch 547/10000\n",
      "113/113 [==============================] - 0s 752us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.9035e-07\n",
      "Epoch 548/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 753us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.9035e-07\n",
      "Epoch 549/10000\n",
      "113/113 [==============================] - 0s 782us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.9035e-07\n",
      "Epoch 550/10000\n",
      "113/113 [==============================] - 0s 785us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 9.9035e-07\n",
      "Epoch 551/10000\n",
      "113/113 [==============================] - 0s 787us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.9228e-07\n",
      "Epoch 552/10000\n",
      "113/113 [==============================] - 0s 754us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.9228e-07\n",
      "Epoch 553/10000\n",
      "113/113 [==============================] - 0s 791us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.9228e-07\n",
      "Epoch 554/10000\n",
      "113/113 [==============================] - 0s 775us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.9228e-07\n",
      "Epoch 555/10000\n",
      "113/113 [==============================] - 0s 778us/step - loss: 0.2337 - accuracy: 0.9102 - val_loss: 0.2860 - val_accuracy: 0.8800 - lr: 7.9228e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss, acc: [0.30050674080848694, 0.8691983222961426]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#Lables = {0: 'crack', 1: 'inclusion', 2: 'pitted'}\n",
    "\n",
    "\n",
    "def print_history(history):\n",
    "    # 绘制训练 & 验证的准确率值\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model accuracy&loss')\n",
    "    # plt.title('Model loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train_acc', 'Val_acc', 'Train_loss', 'Val_loss'])\n",
    "    # plt.legend(['Train_loss', 'Val_loss'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def BP(lr):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(60,)),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.build(input_shape=(None, 60))\n",
    "\n",
    "    #二分类问题： 多分类问题：categorical_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 这里是数据和标签，数据的shape是7，标签one-hot，shape是3\n",
    "\n",
    "    data = []\n",
    "    # 读取数据\n",
    "    raw_data = df[count].values\n",
    "    raw_feature = raw_data\n",
    "\n",
    "    # 数据归一化\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(raw_feature)\n",
    "    scaler.data_max_\n",
    "    raw_feature = scaler.transform(raw_feature)\n",
    "\n",
    "    # 将最后一列的缺陷类别转成one-hot编码形式\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(raw_feature)):\n",
    "        x.append(list(raw_feature[i]))\n",
    "        if df1.iloc[i][1] == 0:\n",
    "            y.append([1, 0])\n",
    "        else:\n",
    "            y.append([0, 1])\n",
    "  \n",
    "   # 随机打乱数据 \n",
    "    \n",
    "  \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    permutation = np.random.permutation(len(x))\n",
    "    x = x[permutation]\n",
    "    y = y[permutation]\n",
    "    # 选取打乱后的前240个数据作为训练数据和验证数据\n",
    "    train_data = x[0:1500]\n",
    "    train_label = y[0:1500]\n",
    "    # 选取打乱后的后60个作为测试数据\n",
    "    test_data = x[1500:]\n",
    "    test_label = y[1500:]\n",
    "\n",
    "\n",
    "    lr = 0.001  #学习率初值，可动态下降\n",
    "    bp_model = BP(lr=lr)\n",
    "\n",
    "    bp_model.summary()\n",
    "\n",
    "    #学习率动态衰减\n",
    "    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                      factor=0.8, patience=5,\n",
    "                                                      min_lr=0.5e-6)\n",
    "\n",
    "    # 早停法，保存训练中的最优参数\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min',\n",
    "                                          verbose=0, patience=100, min_delta=0.0001,\n",
    "                                          restore_best_weights='True')\n",
    "\n",
    "    history = bp_model.fit(train_data, train_label, batch_size=10, epochs=10000, verbose=1,\n",
    "                           callbacks=[lr_reducer, es], validation_split=0.25, shuffle=False)\n",
    "\n",
    "    # 画出四条曲线（训练集和验证集的loss和accuracy缺陷）\n",
    "    print_history(history)\n",
    "    # 训练好的模型，在测试集上的准确率\n",
    "    print('loss, acc:', bp_model.evaluate(test_data, test_label, batch_size=10, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "pre = bp_model.predict(test_data)\n",
    "\n",
    "(pre == pre.max(axis=1, keepdims=1)).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
